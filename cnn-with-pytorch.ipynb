{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8cc663b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-07T05:50:07.484543Z",
     "iopub.status.busy": "2024-11-07T05:50:07.483862Z",
     "iopub.status.idle": "2024-11-07T05:50:12.277720Z",
     "shell.execute_reply": "2024-11-07T05:50:12.276192Z"
    },
    "papermill": {
     "duration": 4.803088,
     "end_time": "2024-11-07T05:50:12.280915",
     "exception": false,
     "start_time": "2024-11-07T05:50:07.477827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "317daa59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T05:50:12.301696Z",
     "iopub.status.busy": "2024-11-07T05:50:12.294295Z",
     "iopub.status.idle": "2024-11-07T05:50:12.306103Z",
     "shell.execute_reply": "2024-11-07T05:50:12.305275Z"
    },
    "papermill": {
     "duration": 0.021136,
     "end_time": "2024-11-07T05:50:12.308378",
     "exception": false,
     "start_time": "2024-11-07T05:50:12.287242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = '/kaggle/input/microsoft-catsvsdogs-dataset/PetImages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4889ec11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T05:50:12.320676Z",
     "iopub.status.busy": "2024-11-07T05:50:12.320368Z",
     "iopub.status.idle": "2024-11-07T05:50:12.324497Z",
     "shell.execute_reply": "2024-11-07T05:50:12.323575Z"
    },
    "papermill": {
     "duration": 0.012609,
     "end_time": "2024-11-07T05:50:12.326505",
     "exception": false,
     "start_time": "2024-11-07T05:50:12.313896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "IGNORE_PATHS = [\n",
    "    '/kaggle/input/microsoft-catsvsdogs-dataset/PetImages/Dog/11702.jpg',\n",
    "    '/kaggle/input/microsoft-catsvsdogs-dataset/PetImages/Cat/666.jpg'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8649cb4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T05:50:12.335717Z",
     "iopub.status.busy": "2024-11-07T05:50:12.335433Z",
     "iopub.status.idle": "2024-11-07T05:50:12.341977Z",
     "shell.execute_reply": "2024-11-07T05:50:12.341056Z"
    },
    "papermill": {
     "duration": 0.01339,
     "end_time": "2024-11-07T05:50:12.343947",
     "exception": false,
     "start_time": "2024-11-07T05:50:12.330557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter valid paths excluding those in IGNORE_PATHS\n",
    "def get_filtered_image_paths(data_dir, ignore_paths):\n",
    "    data_paths = []\n",
    "    for folder in ['Cat', 'Dog']:\n",
    "        folder_path = os.path.join(data_dir, folder)\n",
    "        for filename in os.listdir(folder_path):\n",
    "            filepath = os.path.join(folder_path, filename)\n",
    "            if filepath not in ignore_paths:  # Exclude ignored paths\n",
    "                try:\n",
    "                    img = Image.open(filepath)\n",
    "                    img.verify()  # Verify image integrity\n",
    "                    data_paths.append(filepath)\n",
    "                except (IOError, SyntaxError, Image.UnidentifiedImageError):\n",
    "                    print(f\"Skipping corrupt image: {filepath}\")\n",
    "    return data_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "098cc8e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T05:50:12.352974Z",
     "iopub.status.busy": "2024-11-07T05:50:12.352688Z",
     "iopub.status.idle": "2024-11-07T05:52:44.791015Z",
     "shell.execute_reply": "2024-11-07T05:52:44.789949Z"
    },
    "papermill": {
     "duration": 152.445067,
     "end_time": "2024-11-07T05:52:44.793006",
     "exception": false,
     "start_time": "2024-11-07T05:50:12.347939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping corrupt image: /kaggle/input/microsoft-catsvsdogs-dataset/PetImages/Cat/Thumbs.db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:900: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping corrupt image: /kaggle/input/microsoft-catsvsdogs-dataset/PetImages/Dog/Thumbs.db\n",
      "Total valid images after filtering: 24998\n"
     ]
    }
   ],
   "source": [
    "# Get filtered list of image paths\n",
    "data_paths = get_filtered_image_paths(data_dir, IGNORE_PATHS)\n",
    "print(f\"Total valid images after filtering: {len(data_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0516f958",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T05:52:44.803042Z",
     "iopub.status.busy": "2024-11-07T05:52:44.802730Z",
     "iopub.status.idle": "2024-11-07T05:52:44.808943Z",
     "shell.execute_reply": "2024-11-07T05:52:44.808097Z"
    },
    "papermill": {
     "duration": 0.013245,
     "end_time": "2024-11-07T05:52:44.810812",
     "exception": false,
     "start_time": "2024-11-07T05:52:44.797567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the custom dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_path, transform=None):\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data_path[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")  # Ensure 3 channels\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        label = 0 if \"Dog\" in img_path else 1\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec330d71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T05:52:44.820430Z",
     "iopub.status.busy": "2024-11-07T05:52:44.820118Z",
     "iopub.status.idle": "2024-11-07T05:52:44.824631Z",
     "shell.execute_reply": "2024-11-07T05:52:44.823865Z"
    },
    "papermill": {
     "duration": 0.011439,
     "end_time": "2024-11-07T05:52:44.826526",
     "exception": false,
     "start_time": "2024-11-07T05:52:44.815087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transformation_steps = transforms.Compose([\n",
    "    transforms.Resize((370, 370)),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b014976b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T05:52:44.836093Z",
     "iopub.status.busy": "2024-11-07T05:52:44.835815Z",
     "iopub.status.idle": "2024-11-07T05:52:44.839558Z",
     "shell.execute_reply": "2024-11-07T05:52:44.838763Z"
    },
    "papermill": {
     "duration": 0.010633,
     "end_time": "2024-11-07T05:52:44.841453",
     "exception": false,
     "start_time": "2024-11-07T05:52:44.830820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate the dataset with filtered paths\n",
    "dataset = CustomDataset(data_path=data_paths, transform=transformation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3898efd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T05:52:44.850903Z",
     "iopub.status.busy": "2024-11-07T05:52:44.850615Z",
     "iopub.status.idle": "2024-11-07T05:52:44.880179Z",
     "shell.execute_reply": "2024-11-07T05:52:44.879522Z"
    },
    "papermill": {
     "duration": 0.03636,
     "end_time": "2024-11-07T05:52:44.881956",
     "exception": false,
     "start_time": "2024-11-07T05:52:44.845596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58220373",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T05:52:44.891485Z",
     "iopub.status.busy": "2024-11-07T05:52:44.891171Z",
     "iopub.status.idle": "2024-11-07T05:52:44.895521Z",
     "shell.execute_reply": "2024-11-07T05:52:44.894714Z"
    },
    "papermill": {
     "duration": 0.011104,
     "end_time": "2024-11-07T05:52:44.897269",
     "exception": false,
     "start_time": "2024-11-07T05:52:44.886165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tạo DataLoader cho tập huấn luyện và kiểm tra\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ca5afca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T05:52:44.907194Z",
     "iopub.status.busy": "2024-11-07T05:52:44.906940Z",
     "iopub.status.idle": "2024-11-07T06:42:06.497214Z",
     "shell.execute_reply": "2024-11-07T06:42:06.496213Z"
    },
    "papermill": {
     "duration": 2961.598991,
     "end_time": "2024-11-07T06:42:06.500572",
     "exception": false,
     "start_time": "2024-11-07T05:52:44.901581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 625/625 [04:06<00:00,  2.53it/s]\n",
      "Evaluating: 100%|██████████| 157/157 [00:47<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6718, Test Loss: 0.6195, Test Accuracy: 0.6616\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 625/625 [04:08<00:00,  2.52it/s]\n",
      "Evaluating: 100%|██████████| 157/157 [00:46<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5602, Test Loss: 0.5652, Test Accuracy: 0.7214\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 625/625 [04:09<00:00,  2.50it/s]\n",
      "Evaluating: 100%|██████████| 157/157 [00:46<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3960, Test Loss: 0.5849, Test Accuracy: 0.7284\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 625/625 [04:14<00:00,  2.46it/s]\n",
      "Evaluating: 100%|██████████| 157/157 [00:47<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1580, Test Loss: 1.0617, Test Accuracy: 0.6968\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 625/625 [04:11<00:00,  2.49it/s]\n",
      "Evaluating: 100%|██████████| 157/157 [00:46<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0474, Test Loss: 1.5859, Test Accuracy: 0.7084\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 625/625 [04:08<00:00,  2.51it/s]\n",
      "Evaluating: 100%|██████████| 157/157 [00:46<00:00,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0303, Test Loss: 1.7941, Test Accuracy: 0.6930\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 625/625 [04:10<00:00,  2.50it/s]\n",
      "Evaluating: 100%|██████████| 157/157 [00:46<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0219, Test Loss: 1.9827, Test Accuracy: 0.7146\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 625/625 [04:08<00:00,  2.51it/s]\n",
      "Evaluating: 100%|██████████| 157/157 [00:46<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0201, Test Loss: 2.1381, Test Accuracy: 0.7040\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 625/625 [04:09<00:00,  2.51it/s]\n",
      "Evaluating: 100%|██████████| 157/157 [00:45<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0175, Test Loss: 2.2480, Test Accuracy: 0.7194\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 625/625 [04:10<00:00,  2.50it/s]\n",
      "Evaluating: 100%|██████████| 157/157 [00:45<00:00,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0097, Test Loss: 2.2595, Test Accuracy: 0.7150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm  # For progress tracking\n",
    "\n",
    "# Define the SimpleCNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self._flattened_size = self._get_flattened_size()\n",
    "        self.fc1 = nn.Linear(self._flattened_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)  # Two classes: Cat and Dog\n",
    "\n",
    "    def _get_flattened_size(self):\n",
    "        x = torch.zeros(1, 3, 370, 370)  # Dummy input to calculate size\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        return x.numel()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, self._flattened_size)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Define the ComplexCNN model\n",
    "class ComplexCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ComplexCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self._flattened_size = self._get_flattened_size()\n",
    "        self.fc1 = nn.Linear(self._flattened_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 2)\n",
    "\n",
    "    def _get_flattened_size(self):\n",
    "        x = torch.zeros(1, 3, 370, 370)  # Dummy input to calculate size\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        return x.numel()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, self._flattened_size)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Function to train the model\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(train_loader)\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            test_loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "    return test_loss / len(test_loader), accuracy\n",
    "\n",
    "# Set up training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ComplexCNN().to(device)  # Switch to ComplexCNN() if you want to train the complex model\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 10\n",
    "\n",
    "# Train and evaluate the model\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    train_loss = train(model, train_loader, criterion, optimizer, device)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader, criterion, device)\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe21b20d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T06:42:07.748158Z",
     "iopub.status.busy": "2024-11-07T06:42:07.747499Z",
     "iopub.status.idle": "2024-11-07T07:23:09.947704Z",
     "shell.execute_reply": "2024-11-07T07:23:09.946664Z"
    },
    "papermill": {
     "duration": 2462.844558,
     "end_time": "2024-11-07T07:23:09.950694",
     "exception": false,
     "start_time": "2024-11-07T06:42:07.106136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 81.8MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 625/625 [03:16<00:00,  3.18it/s]\n",
      "Evaluating: 100%|██████████| 157/157 [00:49<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1515, Test Loss: 0.0763, Test Accuracy: 0.9730\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 625/625 [03:16<00:00,  3.19it/s]\n",
      "Evaluating: 100%|██████████| 157/157 [00:48<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0900, Test Loss: 0.0775, Test Accuracy: 0.9686\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 625/625 [03:16<00:00,  3.18it/s]\n",
      "Evaluating: 100%|██████████| 157/157 [00:48<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0825, Test Loss: 0.0568, Test Accuracy: 0.9786\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 625/625 [03:17<00:00,  3.16it/s]\n",
      "Evaluating: 100%|██████████| 157/157 [00:48<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0782, Test Loss: 0.0997, Test Accuracy: 0.9606\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 625/625 [03:16<00:00,  3.18it/s]\n",
      "Evaluating: 100%|██████████| 157/157 [00:49<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0795, Test Loss: 0.0537, Test Accuracy: 0.9778\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 625/625 [03:17<00:00,  3.17it/s]\n",
      "Evaluating: 100%|██████████| 157/157 [00:49<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0685, Test Loss: 0.0520, Test Accuracy: 0.9796\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 625/625 [03:16<00:00,  3.18it/s]\n",
      "Evaluating: 100%|██████████| 157/157 [00:48<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0756, Test Loss: 0.0516, Test Accuracy: 0.9796\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 625/625 [03:18<00:00,  3.15it/s]\n",
      "Evaluating: 100%|██████████| 157/157 [00:49<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0727, Test Loss: 0.0527, Test Accuracy: 0.9794\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 625/625 [03:17<00:00,  3.17it/s]\n",
      "Evaluating: 100%|██████████| 157/157 [00:48<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0670, Test Loss: 0.0595, Test Accuracy: 0.9764\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 625/625 [03:17<00:00,  3.17it/s]\n",
      "Evaluating: 100%|██████████| 157/157 [00:49<00:00,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0695, Test Loss: 0.0522, Test Accuracy: 0.9800\n",
      "Pretrained model saved to pretrained_cnn_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "# Define a function to load and fine-tune a pretrained model\n",
    "def get_pretrained_model():\n",
    "    # Load ResNet18 pre-trained on ImageNet\n",
    "    model = models.resnet18(pretrained=True)\n",
    "\n",
    "    # Freeze all the layers except the final fully connected layer\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Modify the final fully connected layer to output 2 classes (Cat and Dog)\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, 2)  # Output layer for 2 classes\n",
    "\n",
    "    return model\n",
    "\n",
    "# Load the pretrained model\n",
    "model = get_pretrained_model().to(device)\n",
    "\n",
    "# Use CrossEntropyLoss and Adam optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)  # Only optimize the final layer\n",
    "\n",
    "# Train and evaluate the model again with the pretrained model\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    train_loss = train(model, train_loader, criterion, optimizer, device)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader, criterion, device)\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Save the fine-tuned model\n",
    "torch.save(model.state_dict(), 'pretrained_cnn_model.pth')\n",
    "print(\"Pretrained model saved to pretrained_cnn_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 550917,
     "sourceId": 1003830,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5587.598927,
   "end_time": "2024-11-07T07:23:12.431865",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-07T05:50:04.832938",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
